{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import laUtilities as ut\n",
    "import slideUtilities as sl\n",
    "import demoUtilities as dm\n",
    "import pandas as pd\n",
    "from importlib import reload\n",
    "from datetime import datetime\n",
    "from IPython.display import Image\n",
    "from IPython.display import display_html\n",
    "from IPython.display import display\n",
    "from IPython.display import Math\n",
    "from IPython.display import Latex\n",
    "from IPython.display import HTML\n",
    "reload(sl)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       " .container.slides .celltoolbar, .container.slides .hide-in-slideshow {\n",
       "    display: None ! important;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    " .container.slides .celltoolbar, .container.slides .hide-in-slideshow {\n",
    "    display: None ! important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "%Set up useful MathJax (Latex) macros.\n",
    "%See http://docs.mathjax.org/en/latest/tex.html#defining-tex-macros\n",
    "%These are for use in the slideshow\n",
    "$\\newcommand{\\mat}[1]{\\left[\\begin{array}#1\\end{array}\\right]}$\n",
    "$\\newcommand{\\vx}{{\\mathbf x}}$\n",
    "$\\newcommand{\\hx}{\\hat{\\mathbf x}}$\n",
    "$\\newcommand{\\vbt}{{\\mathbf\\beta}}$\n",
    "$\\newcommand{\\vy}{{\\mathbf y}}$\n",
    "$\\newcommand{\\vz}{{\\mathbf z}}$\n",
    "$\\newcommand{\\R}{{\\mathbb{R}}}$\n",
    "$\\newcommand{\\vu}{{\\mathbf u}}$\n",
    "$\\newcommand{\\vv}{{\\mathbf v}}$\n",
    "$\\newcommand{\\vw}{{\\mathbf w}}$\n",
    "$\\newcommand{\\col}{{\\operatorname{Col}}}$\n",
    "$\\newcommand{\\nul}{{\\operatorname{Nul}}}$\n",
    "$\\newcommand{\\vb}{{\\mathbf b}}$\n",
    "$\\newcommand{\\va}{{\\mathbf a}}$\n",
    "$\\newcommand{\\ve}{{\\mathbf e}}$\n",
    "$\\newcommand{\\setb}{{\\mathcal{B}}}$\n",
    "$\\newcommand{\\rank}{{\\operatorname{rank}}}$\n",
    "$\\newcommand{\\vp}{{\\mathbf p}}$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "\\newcommand{\\mat}[1]{\\left[\\begin{array}#1\\end{array}\\right]}\n",
    "\\newcommand{\\vx}{{\\mathbf x}}\n",
    "\\newcommand{\\hx}{\\hat{\\mathbf x}}\n",
    "\\newcommand{\\vbt}{{\\mathbf\\beta}}\n",
    "\\newcommand{\\vy}{{\\mathbf y}}\n",
    "\\newcommand{\\vz}{{\\mathbf z}}\n",
    "\\newcommand{\\vb}{{\\mathbf b}}\n",
    "\\newcommand{\\vu}{{\\mathbf u}}\n",
    "\\newcommand{\\vv}{{\\mathbf v}}\n",
    "\\newcommand{\\vw}{{\\mathbf w}}\n",
    "\\newcommand{\\va}{{\\mathbf a}}\n",
    "\\newcommand{\\ve}{{\\mathbf e}}\n",
    "\\newcommand{\\vp}{{\\mathbf p}}\n",
    "\\newcommand{\\R}{{\\mathbb{R}}}\n",
    "\\newcommand{\\col}{{\\operatorname{Col}}}\n",
    "\\newcommand{\\nul}{{\\operatorname{Nul}}}\n",
    "\\newcommand{\\rank}{{\\operatorname{rank}}}\n",
    "\\newcommand{\\setb}{{\\mathcal{B}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A number is a mathematical concept -- an abstract idea.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> God made the integers, all else is the work of man.\n",
    "\n",
    "-- Leopold Kronecker (1823 - 1891)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "In a computer we assign __bit patterns__ to correspond to certain numbers.   \n",
    "\n",
    "We say the bit pattern is the number's _representation._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For example the number '3.14' might have the representation '01000000010010001111010111000011'.\n",
    "\n",
    "For reasons of efficiency, we use a fixed number of bits for these representations.   In most computers nowadays we use __64 bits__ to represent a number.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For the most part, using integers is not complicated.    \n",
    "\n",
    "Integer representation is essentially the same as binary numerals.  \n",
    "\n",
    "For example, in a 64-bit computer, the representation of the concept of 'seven' would be '0..0111' (with 61 zeros in the front).\n",
    "\n",
    "There is a size limit on the largest value that can be stored as an integer, but it's so big we don't need to concern ourselves with it in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So for our purposes, an integer can be stored exactly.\n",
    "\n",
    "In other words, there is an 1-1 correspondence between every representation and the corresponding integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So, what happens when we compute with integers?\n",
    "\n",
    "For (reasonably sized) integers, computation is __exact__ .... as long as it only involves __addition, subtraction, and multiplication.__  \n",
    "\n",
    "In other words, there are no errors introduced when adding, subtracting or multiplying integers.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, it is a different story when we come to division, because the integers are not closed under division.\n",
    "\n",
    "For example, 2/3 is not an integer.   ... It is, however, a __real__ number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Real Numbers and Floating-Point Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Representing a real number in a computer is a __much__ more complicated matter.   \n",
    "\n",
    "In fact, for many decades after electronic computers were developed, there was no accepted \"best\" way to do this!   \n",
    "\n",
    "Eventually (in the 1980s) a widely accepted standard emerged, called IEEE-754.  This is what almost all computers now use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The style of representation used is called __floating point.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Conceptually, it is similar to \"scientific notation.\"\n",
    "\n",
    "$$123456 = \\underbrace{1.23456}_{significand}\\times {\\underbrace{10}_{base}}^{\\overbrace{5}^{exponent}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Except that it is encoded in binary:\n",
    "\n",
    "$$17 = \\underbrace{1.0001}_{significand}\\times {\\underbrace{2}_{base}}^{\\overbrace{4}^{exponent}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The sign, significand, and exponent are all contained within the 64 bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"9dfdac998a188749\"></div>\n",
       "    <script type=\"text/javascript\">\n",
       "        $(function(){\n",
       "            var p = $(\"#9dfdac998a188749\");\n",
       "            if (p.length==0) return;\n",
       "\n",
       "            while (!p.hasClass(\"cell\")) {\n",
       "                p=p.parent();\n",
       "\n",
       "                if (p.prop(\"tagName\") ==\"body\") return;\n",
       "            }\n",
       "            var cell = p;\n",
       "            cell.find(\".input\").addClass(\"hide-in-slideshow\")\n",
       "        });\n",
       "    </script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmoAAAB9CAYAAAASnk91AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEmSJEmSJEmSJEmSJEmSJEmSJEnqpP8HttWgCntFnXMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "image/png": {
       "width": 450
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sl.hide_code_in_slideshow()\n",
    "display(Image(\"images/IEEE_754_Double_Floating_Point_Format.png\", width=450))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='1'> By Codekaizen (Own work) [<a href=\"http://www.gnu.org/copyleft/fdl.html\">GFDL</a> or <a href=\"http://creativecommons.org/licenses/by-sa/4.0-3.0-2.5-2.0-1.0\">CC BY-SA 4.0-3.0-2.5-2.0-1.0</a>], <a href=\"https://commons.wikimedia.org/wiki/File%3AIEEE_754_Double_Floating_Point_Format.svg\">via Wikimedia Commons</a></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Because only a fixed number of bits are used, __most real numbers cannot be represented exactly in a computer.__\n",
    "\n",
    "Another way of saying this is that, usually, a floating point number is an approximation of some particular real number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Generally when we try to store a real number in a computer, __what we wind up storing is the closest floating point number that the computer can represent.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##Rules for Working with Floating Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The way to think about working with floating point (in fact, how the hardware actually does it) is:\n",
    "\n",
    "1. Represent each input as the __nearest__ representable floating point number.\n",
    "2. Compute the result exactly from the floating point representations.\n",
    "3. Return the __nearest__ representable floating point number to the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What does \"__nearest__\" mean?   Long story short, it means \"round to the nearest representable value.\"\n",
    "\n",
    "Let's say we have a particular real number $r$ and we represent it as a floating point value $f$.   \n",
    "\n",
    "Then $r = f + \\epsilon$ where $\\epsilon$ is the amount that $r$ was rounded when represented as $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How big can epsilon be?  Let's say $f$ is\n",
    "\n",
    "$$f = \\underbrace{1.010...01}_{53~bits}\\times 2^n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then $|\\epsilon|$ must be smaller than $$|\\epsilon| < \\underbrace{0.000...01}_{53~bits}\\times 2^n$$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So as a _relative error_, \n",
    "\n",
    "$$ \\mbox{relative error} = \\frac{|\\epsilon|}{f} < \\frac{{0.000...01}\\times 2^n}{\\underbrace{1.000...00}_{53~bits}\\times 2^n} = 2^{-52} \\approx 10^{-16}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Problems arise when we work with floating point numbers and confuse them with real numbers, thereby forgetting that most of the time we are not storing the real number exactly, but only a floating point number that is close to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's look at some examples.  First:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ((1/8)*8)-1\n",
    "a = 1/8\n",
    "b = 8\n",
    "c = 1\n",
    "(a*b)-c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It turns out that 1/8, 8, and 1 can all be stored exactly in IEEE-754 floating point format.\n",
    "\n",
    "So, we are \n",
    "* storing the inputs exactly (1/8, 8 and 1)\n",
    "* computing the results exactly (by definition of IEEE-754), yielding $(1/8) * 8 = 1$\n",
    "* and representing the result exactly (zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "OK, here is another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ((1/7)*7)-1\n",
    "a = 1/7\n",
    "b = 7\n",
    "c = 1\n",
    "a * b - c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here the situation is different. \n",
    "\n",
    "1/7 can __not__ be stored exactly in IEEE-754 floating point format.\n",
    "\n",
    "In binary, 1/7 is $0.001\\overline{001}$, an infinitely repeating pattern that clearly cannot be represented in a finite sequence of bits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Nonetheless, the computation $(1/7)*7$ still yields exactly 1.0.\n",
    "\n",
    "Why? Because the rounding of $0.001\\overline{001}$ to its closest floating point representation, when multiplied by 7, yields a value whose closest floating point representation is 1.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now, let's do something that seems very similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.3877787807814457e-17"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ((1/70)*7)-0.1\n",
    "a = 1/70\n",
    "b = 7\n",
    "c = 0.1\n",
    "a * b - c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In this case, both 1/70 and 0.1 __cannot__ be stored exactly.    \n",
    "\n",
    "More importantly, the process of rounding 1/70 to its closest floating point representation, then multiplying by 7, yields a number whose closest floating point representation is __not__ 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, that floating point representation is very __close__ to 0.1.   \n",
    "\n",
    "Let's look at the difference: -1.3877787807814457e-17.  \n",
    "\n",
    "This is about $-1 \\cdot 10^{-17}$.\n",
    "\n",
    "In other words, -0.0000000000000001\n",
    "\n",
    "Compared to 0.1, this is a very small number.  The relative error abs(-0.0000000000000001 / 0.1) is about $10^{-16}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This suggests that when a floating point calculation is not exact, the error (in a relative sense) is usually very small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice also that in our example the size of the relative error is about $10^{-16}$.   \n",
    "\n",
    "Recall that the significand in IEEE-754 uses 52 bits and that $2^{-52} \\approx 10^{-16}$.\n",
    "\n",
    "One way of thinking about this is that you __only have about 16 digits of accuracy__ in a floating point number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Special Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three kinds of special values defined by IEEE-754:\n",
    "1.  NaN, which means \"Not a Number\" \n",
    "2.  Infinity -- both positive and negative\n",
    "3.  Zero -- both positive and negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__NaN__ and __Inf__ behave about as you'd expect.  If you get one of these values in a computation you should be able to reason about how it happened.   Note that these are values, and can be assigned to variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = np.log(0)\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As far as we are concerned, there is no difference between positive and negative zero.   You can ignore the minus sign in front of a negative zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = np.nan\n",
    "var + 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = np.inf\n",
    "var + 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mathematical \"Computation\" and _Actual_ Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In a mathematical theorem, working with (idealized) numbers, it is always true that:\n",
    "\n",
    "If $c = 1/a$, then $abc = b.$\n",
    "\n",
    "In other words, $(ab)/a = b.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's test whether this is always true in actual computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 7\n",
    "b = 1/10\n",
    "c = 1/a\n",
    "a*c*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09999999999999999"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b*c*a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*c*b == b*c*a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here is another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30000000000000004"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.1 + 0.1 + 0.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.551115123125783e-17"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 * (0.1) - 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Principle 1: Do not compare floating point numbers for equality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Two floating point computations that _should_ yield the same result mathematically, may not do so due to rouding error.\n",
    "\n",
    "However, in general, if two numbers should be equal, the relative error of the difference in the floating point should be small.\n",
    "\n",
    "So, instead of asking whether two floating numbers are equal, we should ask whether the relative error of their difference is small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3877787807814457e-16"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 = a * b * c\n",
    "r2 = b * c * a\n",
    "np.abs(r1-r2)/r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "finfo(resolution=1e-15, min=-1.7976931348623157e+308, max=1.7976931348623157e+308, dtype=float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.finfo('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(r1 == r2)\n",
    "print(np.abs(r1-r2)/r1 < np.finfo('float').resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Principle 2: Beware of ill-conditioned problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An __ill-conditioned__ problem is one in which the outputs depend in a very sensitive manner on the inputs.  \n",
    "\n",
    "That is, a small change in the inputs can yield a very large change in the outputs.\n",
    "\n",
    "The simplest example is computing $1/(a-b)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "7.205759403792794e+16\n",
      "9999.999999998327\n"
     ]
    }
   ],
   "source": [
    "print(r1)\n",
    "r3 = r1 + 0.0001\n",
    "print(1/(r1-r2))\n",
    "print(1/(r3-r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Because the inputs to your problem may not be exact, if the problem is ill-conditioned, the outputs may be wrong by a large amount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Principle 3: Relative error can be magnified during subtractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Two numbers, each with small relative error, can yield a value with large relative error if subtracted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's say we represent a = 1.2345 as 1.2345002 -- the relative error is 0.0000002."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's say we represent b = 1.234  as 1.2340001 -- the relative error is 0.0000001."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now, subtract a - b: the result is .0005001.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What is the relative error?  0.005001 - 0.005 / 0.005 = 0.0002  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The relative error of the result is 1000 times larger than the relative error of the inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here's an example in practice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9e-08\n",
      "8.999999989711682e-08\n",
      "1.14314640119e-09\n"
     ]
    }
   ],
   "source": [
    "a = 1.23456789\n",
    "b = 1.2345678\n",
    "print(0.00000009)\n",
    "print(a-b)\n",
    "print(np.abs(a-b-0.00000009)/ 0.00000009)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know the relative error in the inputs is on the order of $10^{-16}$, but the relative error of the output is on the order of $10^{-9}$ -- i.e., a million times larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A good summary that covers additional issues is at https://docs.python.org/2/tutorial/floatingpoint.html. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
